---
title: Do you follow best practices for prompt caching?
uri: do-you-follow-best-practices-for-prompt-caching
categories:
  - category: categories/artificial-intelligence/rules-to-better-ai-development.mdx
authors:
  - title: Michael Smedley
    url: 'https://www.ssw.com.au/people/michael-smedley/'
related:
  - {}
guid: 59c83e62-5c27-4bd4-9d90-6f774983acac
seoDescription: 'Learn best practices for prompt caching in OpenAI-style workflows, including deterministic prefixes, cache key design, tool stability, and instrumentation for maximum performance and cost efficiency.'
created: 2026-02-19T23:48:44.539Z
createdBy: Mike
createdByEmail: michaelsmedley@ssw.com.au
lastUpdated: 2026-02-20T04:13:32.408Z
lastUpdatedBy: Mike
lastUpdatedByEmail: michaelsmedley@ssw.com.au
---

You ship a new AI feature and expect costs and latency to drop thanks to prompt caching — but nothing changes. After investigation, you discover that a timestamp in the system prompt or a small tool schema change invalidated the cache on every request. Small structural mistakes can completely eliminate caching benefits.

<endIntro />

Prompt caching (such as OpenAI-style implicit KV caching) can dramatically reduce latency and cost — but only if your prompts are structured deliberately. Follow these rules to maximize cache hit rates and keep your architecture efficient.

## Treat the prompt like a deterministic artifact

Caching requires an identical, contiguous prefix. Even minor differences break reuse.

<boxEmbed
  body={<>
    ✅ Do
    
    * Keep your system prompt static
    * Keep tool definitions and schemas stable
    * Maintain identical ordering of messages
    * Ensure consistent whitespace and formatting
  </>}
  figurePrefix="none"
  figure=""
  style="highlight"
/>

<boxEmbed
  body={<>
    ❌ Don’t
    
    * Inject timestamps or random IDs near the beginning
    * Reorder tools or messages
    * Introduce small per-request formatting differences
  </>}
  figurePrefix="none"
  figure=""
  style="highlight"
/>

<boxEmbed
  body={<>
    System: You are a helpful assistant. Timestamp: 2026-02-20T10:15:32Z
  </>}
  figurePrefix="bad"
  figure="Bad Example - A dynamic timestamp changes the prefix every request and prevents cache reuse "
  style="greybox"
/>

## Put dynamic content as late as possible

Structure prompts as:

1\. System prompt (static)

2\. Tool definitions / schemas (static)

3\. User/org configuration (semi-static)

4\. Current user task (dynamic)

5\. Tool outputs / new turns (dynamic)

This “static-first, dynamic-last” layout maximizes reusable prefix length.

<boxEmbed
  body={<>
    Keep globally reusable content first, then user-scoped context, then task-scoped data.
  </>}
  figurePrefix="none"
  figure=""
  style="tips"
/>

## Never edit earlier turns — append instead

Once a conversation starts, avoid rewriting history.

<boxEmbed
  body={<>
    ❌ Don’t
    
    Rewrite an earlier message to “fix” intent.
  </>}
  figurePrefix="none"
  figure=""
  style="greybox"
/>

<boxEmbed
  body={<>
    ✅ Do
    
    Append a new message:
    
    \> “Update: User intent changed. Please do X instead.”
  </>}
  figurePrefix="none"
  figure=""
  style="greybox"
/>

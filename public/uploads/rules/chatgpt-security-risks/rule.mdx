---
type: rule
title: Do you know the potential security risks of using ChatGPT?
categories:
- category: categories/artificial-intelligence/rules-to-better-chatgpt-prompt-engineering.mdx
seoDescription: ChatGPT security risks include data breaches and unauthorized access
  to confidential information, while best practices involve not sharing sensitive
  info and monitoring data retention policies.
uri: chatgpt-security-risks
authors:
- author: ulysses-maclaren
created: 2023-05-16 14:47:50.644000
guid: 9eddfea2-3870-4814-8097-ddbf68afaa36
---
ChatGPT is an AI language model developed by OpenAI that is considered generally safe due to the implementation of various security measures, data handling practices, and privacy policies. However, users should be aware of potential risks and follow best practices when using the platform.

<imageEmbed
  alt="Image"
  size="large"
  showBorder={false}
  figurePrefix="good"
  figure="Good Example - You want to use your tools safely!"
  src="/uploads/rules/chatgpt-security-risks/safe-dev.jpg"
/>


OpenAI is a third-party platform and you should not make assumptions about how they process or retain data. They will also likely be able to change their policies from time to time so even if something is stated today it might be different tomorrow.

You should never submit any confidential information into ChatGPT. Specifically, you should never submit any information which identifies or could potentially be used to identify an individual (E.g. name, address, date of birth, phone number etc.)

<endIntro />

Key points:

* Security measures by OpenAI:

  * Encryption
  * Access controls
  * External security audits
  * Bug bounty program
  * Incident response plans
* Responsible data handling practices by OpenAI:

  * Transparency about data collection purposes
  * Data storage and retention policies (30 days)
  * Controlled data sharing with third parties
  * Compliance with regional data protection regulations
  * Respecting user rights and control over their data
* ChatGPT is not confidential:

  * All conversations are used as training data by default, but this can be turned off
  * Users should avoid sharing sensitive information


<imageEmbed
  alt="Image"
  size="large"
  showBorder={false}
  figurePrefix="none"
  figure="Toggle Your Name | Settings | Data controls | Improve the model for everyone to stop the model training on your data"
  src="/uploads/rules/chatgpt-security-risks/trainingondata.png"
/>


* Potential risks of using ChatGPT:

  * Data breaches
  * Unauthorized access to confidential information
  * Biased or inaccurate information generation
* Best practices for using ChatGPT:

  * Do not share or submit sensitive or confidential information on ChatGPT, ever
  * Review privacy policies of platforms using ChatGPT
  * Use anonymous or pseudonymous accounts
  * Monitor data retention policies
* Current regulations:

  * No specific regulations for AI systems like ChatGPT
  * Compliance with existing data protection and privacy regulations (e.g., GDPR, CCPA)
  * Proposed AI Act could become the first comprehensive regulation for AI technologies

Always exercise caution when using ChatGPT and avoid sharing sensitive information, as data retention policies and security measures can only provide a certain level of protection.
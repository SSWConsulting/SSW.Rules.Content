---
tips: ''
type: rule
title: Do you use AI to edit images?
uri: use-ai-to-edit-images
categories:
  - category: categories/artificial-intelligence/rules-to-better-ai-generated-media.mdx
authors:
  - title: Louis Roa
    url: 'https://www.ssw.com.au/people/louis-roa/'
  - title: Luke Cook
    url: 'https://www.ssw.com.au/people/luke-cook/'
  - title: Alex Blum
    url: 'https://ssw.com.au/people/alex-blum'
related:
  - rule: public/uploads/rules/the-best-ai-image-generators/rule.mdx
  - rule: public/uploads/rules/when-to-use-ai-generated-images/rule.mdx
guid: 7cfc7a26-778f-4159-a8fc-de0ea4c73d60
seoDescription: >-
  Learn when and how to use AI to edit images—what it’s good for, common
  pitfalls, ethical labeling, and battle-tested prompt patterns that preserve
  identity and make precise, localized changes
created: 2025-09-04T04:35:12.000Z
createdBy: Louis Roa
createdByEmail: 149936952+louisroa8189@users.noreply.github.com
lastUpdated: 2026-01-02T05:15:46.405Z
lastUpdatedBy: 'Alex Blum [SSW]'
lastUpdatedByEmail: alexblum@ssw.com.au
isArchived: false
---

You've probably seen AI churn out gorgeous images from a sentence... then watched it **ruin** a photo when you asked for a tiny tweak.

Teams waste time regenerating whole scenes, your subject look-alike drifts between edits, and brand consistency suffers. Modern **editing-first** AI models fix this by making **targeted, local edits** while preserving everything else, so you can remove a bin, change the background, or adjust a shirt color without re-generating the whole shot.

<endIntro />

<youtubeEmbed url="https://www.youtube.com/watch?v=8_GgeASwHwQ" description="Video: Google’s nano banana just killed Photoshop... let’s run it (3 min)" />

## When should you use AI to edit images?

Use AI editing when you need **surgical changes** and fast iteration:

* Remove or replace small elements (e.g. "remove the chair in the background")
* Background swaps and extensions (outpainting), canvas cleanup, or sky replacement
* Consistent variations for marketing (same product/person, different scenes)
* Style harmonization (color matching, lighting tweaks, subtle restyling)
* Text fixes in images (signs, labels) when allowed

Avoid or get explicit approval for:

* Sensitive content (medical, legal/forensic, news)
* Deceptive changes (e.g. misrepresenting events)
* Portrait retouching without consent or policy coverage

## From text-to-image to intelligent editing

### Early days (2022)

**Text-to-image models** like DALL·E 2, Imagen, and Midjourney popularized "prompt to picture" and introduced basic inpainting/outpainting. Great for creation, but edits often **regenerated the whole image**, causing drift and detail loss.

<imageEmbed alt="Image" size="medium" showBorder={true} figurePrefix="bad" figure="Bad example - Text to image models often struggle with accuracy, producing distorted anatomy and other artifacts when asked to edit an image, e.g. The Terminator only has 3 fingers..." src="/uploads/rules/use-ai-to-edit-images/comewith-me-messed-up.png" />

## Editing-first image models (what’s changed)

Editing-first models such as **[Nano Banana Pro](https://gemini.google/overview/image-generation/), [FLUX.1 Kontext](https://bfl.ai/models/flux-kontext) and [GPT Image 1.5](https://openai.com/index/new-chatgpt-images-is-here/)** let you take an existing image and make specific changes using simple, plain-language instructions. They keep the main subject and overall scene intact, follow instructions closely, and allow you to refine changes step by step without reducing image quality. 

In practice, this feels similar to using Photoshop, but by describing what you want in words instead of using tools.

<imageEmbed alt="Image" size="large" showBorder={true} figurePrefix="good" figure="Good example - You can take an existing image and ask Nano Banana to create new images using it as a reference, then refine them conversationally by asking for changes" src="/uploads/rules/use-ai-to-edit-images/penny-nano-banana.png" />

### What makes editing-first models different?

1. **Targeted edits** – They change only what you ask for and leave everything else as-is. This makes them practical for real work where accuracy matters.
2. **Consistency and identity preservation** – The same person or product stays recognisable across edits, even when changing things like clothing, backgrounds, or styling.
3. **Clear instruction following** – They do what you ask without making extra, unexpected changes. If you ask to change the shirt colour, only the shirt changes.
4. **Iterative & interactive** – You can chain edits (clean background → add shadow → tweak contrast) without the image falling apart or losing quality.
5. **Context awareness** – The model remembers what you’ve already changed, so you don’t have to repeat yourself each time.

## Nano Banana Pro (Google)

[Nano Banana Pro](https://gemini.google/overview/image-generation/) is Google’s high-end image model built on Gemini Pro, with a strong focus on **realism**, **sharpness**, and **precision**. It excels at editing real photos, rendering clean and accurate text inside images, and producing **visually** **consistent** results. 

Based on user feedback, it's more trusted for serious visual work, describing it as polished and reliable rather than fast or playful. It supports higher-resolution outputs and feels designed for situations where the image needs to look finished, not exploratory.

### Best for

* Photo-realistic images
* Editing and enhancing real photos
* High-quality marketing and brand visuals
* Accurate text inside images
* Posters, ads, and presentation graphics
* Print-ready, high-resolution output
* Final, client-ready visuals

<imageEmbed alt="Image" size="large" showBorder={true} figurePrefix="good" figure="Good example - You can even ask it to change the perspective of an image" src="/uploads/rules/use-ai-to-edit-images/gzsnzhtwoaapceg.jpg" />

<imageEmbed alt="Image" size="large" showBorder={true} figurePrefix="good" figure="Good example - You can isolate a character from an image as seen in this example from Google" src="/uploads/rules/use-ai-to-edit-images/gzwtouzbyaamxak.jpg" />

## GPT Image 1.5 (OpenAI)

[GPT Image 1.5](https://openai.com/index/new-chatgpt-images-is-here/) is OpenAI’s latest image generation and editing model, built directly into ChatGPT and available via API. It prioritises **speed**, **lower cost**, and strong **instruction following**, making it well suited to **iteration-heavy** workflows. It works like a chat-based design assistant that remembers previous instructions, supports targeted edits, and handles text in images more reliably than older OpenAI models. 

User feedback frames it as a major upgrade that’s fast and flexible for creative work, concepts, and experimentation, though still less consistent than Nano Banana Pro for high-realism photo edits.

### Best for

* Fast image generation and iteration
* Small, targeted edits without starting over
* Marketing assets with lots of variations
* Product and UI concepts
* Diagrams and explainers
* Creative exploration and sketching
* Bulk image generation
* Chat-based, back-and-forth workflows

<imageEmbed alt="Image" size="medium" showBorder={true} figurePrefix="good" figure="Good example - An example of OpenAI's image generation" src="/uploads/rules/use-ai-to-edit-images/dark-mermaids.png" />

<boxEmbed
  style="greybox"
  body={<>
    **Prompt example:** *"Tall, vertical gothic-inspired movie poster for a fantasy film set in the Victorian era, featuring three powerful mermaids rising from a dark, stormy ocean near a foggy Victorian harbor. Their long, shimmering mermaid tails are clearly visible beneath Victorian gowns made of black and deep-blue lace and velvet, with corset bodices, high collars, and flowing sleeves that drift as if underwater. Gas lamps, iron railings, and silhouettes of Victorian buildings appear in the background, partially obscured by mist. The lighting is dramatic but not horror: silver moonlight, deep shadows, and glowing teal highlights on the water. Mood is mysterious, elegant, and adventurous. Color palette of deep blues, greens, greys, and inky blacks with silver and teal accents. At the top, the title text in ornate gothic lettering: “Dark Mermaids” and at the bottom a subtle tagline, in smaller elegant serif type. Highly detailed, cinematic, poster art, no studio logos, no extra text."*
  </>}
  figurePrefix="none"
  figure=""
/>

## Midjourney V7

[Midjourney V7](https://www.midjourney.com/home) is built for **high-end visual generation**, not editing-first workflows. Unlike GPT Image 1.5 or Nano Banana Pro, it’s less suited to making precise, localised changes to existing images. Where it shines is pure image creation. V7 is a noticeable leap forward, with better prompt understanding and higher visual quality, especially in textures, anatomy, hands, and complex objects. It’s designed for striking, cinematic, and artistic output rather than step-by-step refinement.

Midjourney remains best when you want a strong visual statement with minimal iteration. It offers multiple generation modes: **Turbo** for speed at a higher cost, **Relax** for slower and cheaper output, and **Draft Mode**, which generates images much faster and cheaper at lower quality, with the option to upscale if the result works.

### Best for

* Cinematic and artistic imagery
* Hero images and landing pages
* Stylised key art
* Mood and concept visuals
* One-off, high-impact images

<imageEmbed alt="Image" size="medium" showBorder={true} figurePrefix="good" figure="Good example - Images are incredibly realistic with Midjourney's v7 on X" src="/uploads/rules/use-ai-to-edit-images/midjourney-post.png" />

## TLDR

* **[Nano Banana Pro](https://gemini.google/overview/image-generation/)** – precise, realistic, client-ready visuals
* **[GPT Image 1.5](https://openai.com/index/new-chatgpt-images-is-here/)** – fast, flexible, great for iteration
* **[Midjourney V7](https://www.midjourney.com/home)** – beautiful, cinematic, high impact one-offs

## Origin & trust (label your edits)

As AI editing becomes standard, origin is essential. SynthID is an industry approach that embeds an imperceptible, pixel-level watermark at generation/edit time (in addition to any visible “AI” label). It’s designed to survive common transforms (compression, mild crops/brightness changes) and can be verified by compatible detectors.

**Best Practices for AI image use:**

* **Enable watermarking** where your stack supports it (e.g. tools that offer SynthID-style invisible marks plus visible "AI-edited" labels)
* **Store proof** of detection alongside the final asset (export the verifier result or checksum)
* **Disclose edits** in captions/metadata ("Edited with AI; objects removed; colors adjusted")
* **Know the limits:** because very tiny edits may be too subtle to flag; keep manual logs regardless

<imageEmbed alt="Image" size="medium" showBorder={true} figurePrefix="good" figure="Good example - Clear disclosure aligned to asset management and brand guidelines that is added to the metadata" src="/uploads/rules/use-ai-to-edit-images/origin-added-to-metadata.png" />

## ⚠️ Common pitfalls and fixes

### Identity drift

The subject (face, object, or brand element) gradually morphs into something unrecognizable after repeated edits.

✨ **The fix:** Re-state constraints each turn (*"keep the same face, same product texture"*). If drift persists, roll back one step and re-edit in smaller increments.

### Over-editing look

Edits pile up until the result looks artificial, plastic, or uncanny.

✨ **The fix:** Prefer subtle adjustments; specify *"natural"* or *"minimal"* in the prompt.

### Perspective mismatches

Inserted or modified objects appear at the wrong scale, angle, or depth compared to the base image.

✨ **The fix:** Add guidance like *"match camera angle and lens feel"*.

### Lighting inconsistency

New elements don’t share the same light source, shadow direction, or color temperature, breaking realism.

✨ **The fix:** Include *"soft shadow matching light direction"* and *"keep global color balance"*.

***

## What SSW thinks about the latest Generative AI tools

The SSW TV team has been exploring how AI is changing design workflows, boosting productivity, and raising the quality bar for everyone creating graphics today.

If you would like more information on AI image generators:

* [Explore more of our AI Shorts on SSWTV](https://www.youtube.com/@SSWTV/shorts)
* [My Top 3 AI Image Generators – Adam Cogan](https://adamcogan.com/2025/11/17/my-top-3-ai-image-generators/)

***

### Nano Banana Pro

<youtubeEmbed url="https://youtu.be/rdnwqBMpiCY?si=vXN4uowYfIHfS-ZZ" description="Video: The AI powerhouse lifting the quality bar for all graphics... Nano Banana Pro (2 min)" />

***

### Nano Banana vs FLUX

<youtubeEmbed url="https://youtube.com/shorts/4eBUQiP4zjI?si=_fb9SiUEhwNVmvKz" description="Video: Open source image model from China, nails what most AIs can’t... FLUX.2 (2 min)" />

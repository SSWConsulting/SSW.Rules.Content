---
type: rule
tips: ""
title: Do you mix user research methods to capture the full picture?
seoDescription: Don’t rely only on 1-on-1 interviews. Mix research methods to
  uncover both personal pain points and shared behaviours across teams.
uri: mix-user-research-methods
authors:
  - title: Betty Bondoc
    url: https://www.ssw.com.au/people/betty-bondoc/
related:
  - test-high-risk-features
  - measure-website-changes-impact
guid: e3427c47-5871-476d-8aaf-e0968edd3cb5
---
Relying on the same user research method like only running 1-on-1 interviews leads to blind spots. Interviews are great for depth, but they don’t reveal group dynamics, cross-team dependencies, or patterns that emerge at scale.

To design experiences that scale, you need insights that are **qualitative** and **quantitative**, **attitudinal** and **behavioural**, and drawn from both **individuals** and **teams**.

<!--endintro-->

## Different research methods

### Attitudinal vs behavioral

**Attitudinal** research captures what users **say** — their opinions, preferences, and perceptions. E.g. User surveys saying a feature is confusing.

**Behavioral** research focuses on what users **actually do** during real interactions. E.g. Usability testing shows users skip the feature entirely.

### Qualitative vs quantitative

**Qualitative** research helps you understand **why** something is happening by exploring deeper motivations and thought processes. E.g. Open-ended interviews reveal frustration with a checkout step.

**Quantitative** research measures **how often** something occurs through numbers and patterns. E.g. Analytics show a 60% drop-off rate on the same step.

### Context of use

The **way users are studied** can vary by how closely it reflects real-world use. E.g. A team conducts in-person usability testing with real customers performing typical tasks in a production app (natural + scripted context).

* **Natural use** observes users in their actual environment. E.g. Field study
* **Scripted tasks** have users perform specific actions. E.g. Usability tests
* **Abstracted activities** use remote or synthetic scenarios E.g. card sorting, A/B tests
  
## Why mix research methods?

According to Nielsen Norman Group, no single method uncovers all UX insights. A mix of approaches leads to better understanding and fewer blind spots.

✅ Mixing research methods helps you:

* Understand both individual workflows and systemic issues
* Avoid designing for edge cases or only the loudest voices
* Uncover hidden workarounds and friction between teams
* Generate more reliable, well-rounded insights

Read the full article: [When to Use Which User-Experience Research Methods](https://www.nngroup.com/articles/which-ux-research-methods/).

`youtube: https://www.youtube.com/watch?v=OtUWbsvCujM`
**Video: When to Use Which UX Research Method (5 min)**

## What methods should I combine?

| Method                         | Use it to                                               |
|-------------------------------|-------------------------------------------------------------|
| **1-on-1 interviews**             | Explore personal workflows and uncover pain points         |
| **Group workshops / focus groups** | Reveal shared behaviors and team-level challenges          |
| **Observation / shadowing**       | Catch things users don’t say (but still do)                |
| **Surveys**                       | Quantify trends or confirm emerging patterns across users  |

You don’t need to use every method on every project, but most projects benefit from using at least two.

## Practical example

::: greybox
A UX designer begins by interviewing three Admins to understand how they use the system. Based on those findings, she runs a 60-minute group workshop with Admins and Technicians to map shared issues and uncover workflow gaps between teams.
:::
::: good
Figure: Good example – Combines depth from interviews with breadth from group insight
:::

::: greybox
Only interviewing one user and assuming their experience applies to everyone. Skipping group validation and relying on stakeholder assumptions.
:::
::: bad
Figure: Bad example – Designs based on limited or biased input
:::

## Bonus tip: Mix user roles, not just methods

Group sessions are a great way to bring in users from different teams, departments, or levels of experience. Doing so can help you uncover:

* Gaps in communication
* Conflicting priorities
* “Unofficial” workarounds users rely on

These types of issues rarely come up in 1-on-1 interviews alone.

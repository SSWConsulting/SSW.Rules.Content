---
type: rule
tips: ""
title: Do you avoid Automation Bias?
seoDescription: Did you know that AI has the potential to make your work worse? Learn the common pitfalls so that AI can help, not hinder.
uri: avoid-automation-bias
authors:
  - title: Eddie Kranz
    url: https://www.ssw.com.au/people/eddie-kranz
related:
  - manage-security-risks-when-adopting-ai-solutions
  - manage-legal-implications-of-ai
  - mitigate-brand-risks-ai
  - use-ai-responsibly
created: 2025-09-16T14:29:00.000Z
guid: 67B27A09-5546-4AD9-9DCC-732CE63D7183
---

AI has been championed as a huge productivity booster, which it is. However, people blindly trusting AI outputs, or preferring them over theirs, can lead to 'automation bias'.
Automation bias describes the impairment of judgement due to a deferred sense of accountability -- "It was the AI's mistake!"

<!--endintro-->
Automation bias is a type of cognitive bias. A thinking shortcut, where we overly rely on machine-generated decisions and forego critical thinking. 
It’s a _brain_ problem, not a _model_ problem (not to be mistaken with **model bias**)

Automation bias is not just an AI problem -- it's an issue wherever a human has used a machine to automate a task.

### Errors from automation bias
 
There are two types of errors made due to confirmation bias:

**Error of commission**: Doing the wrong thing because the system suggested it (e.g. accepting a flawed suggestion, getting ChatGPT to write your essay, etc.)
**Error of omission**: Failing to act because the system didn't flag a problem (e.g. shipping flawed code, because Copilot review OK'ed it)

#### Where automation bias shows up

- **Coding assistants (e.g. Copilot):** They make you faster, not necessarily better. The more complex some generated code appears, the more likely you'll be to click "Accept".
- **Google Search (especially 'AI Overview'):** These search engines are incentivised to return the most **relevant** content, rather than the most **correct** content.
- **GPS Navigation:** Countless cases of people driving their car into water 'because the app told them to'.

#### Why do we fall for it?

##### Task complexity + time pressure

Under stress, cognition narrows. AI tools promise “do less work,” which quickly becomes “do more work in the same time,” amplifying over-reliance.

##### Social aspects & accountability


If there are two people within a company who don't know each other well, and review each other's code, 